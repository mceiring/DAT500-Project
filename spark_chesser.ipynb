{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries #\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql.functions import split, col, array_contains, translate, round, size, when, udf, lit, mean, count, format_number, collect_list\n",
    "from pyspark.sql.types import TimestampType, MapType, IntegerType, StringType, ArrayType, FloatType, StructField, StructType\n",
    "from pyspark.sql import SparkSession\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m spark \u001b[39m=\u001b[39m SparkSession\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mappName(\u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mmaster(\u001b[39m\"\u001b[39;49m\u001b[39myarn\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[1;32m      2\u001b[0m \u001b[39m.\u001b[39;49mconfig(\u001b[39m\"\u001b[39;49m\u001b[39mspark.executor.instances\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m9\u001b[39;49m) \\\n\u001b[1;32m      3\u001b[0m \u001b[39m.\u001b[39;49mconfig(\u001b[39m\"\u001b[39;49m\u001b[39mspark.executor.memory\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m1G\u001b[39;49m\u001b[39m\"\u001b[39;49m)  \\\n\u001b[1;32m      4\u001b[0m \u001b[39m.\u001b[39;49mconfig(\u001b[39m\"\u001b[39;49m\u001b[39mspark.ui.port\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m8080\u001b[39;49m) \\\n\u001b[1;32m      5\u001b[0m \u001b[39m.\u001b[39;49mgetOrCreate()\n",
      "File \u001b[0;32m~/spark/python/pyspark/sql/session.py:269\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m     sparkConf\u001b[39m.\u001b[39mset(key, value)\n\u001b[1;32m    268\u001b[0m \u001b[39m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m sc \u001b[39m=\u001b[39m SparkContext\u001b[39m.\u001b[39;49mgetOrCreate(sparkConf)\n\u001b[1;32m    270\u001b[0m \u001b[39m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[39m# by all sessions.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m session \u001b[39m=\u001b[39m SparkSession(sc, options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options)\n",
      "File \u001b[0;32m~/spark/python/pyspark/context.py:483\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[39mwith\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    482\u001b[0m     \u001b[39mif\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_active_spark_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 483\u001b[0m         SparkContext(conf\u001b[39m=\u001b[39;49mconf \u001b[39mor\u001b[39;49;00m SparkConf())\n\u001b[1;32m    484\u001b[0m     \u001b[39massert\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_active_spark_context \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    485\u001b[0m     \u001b[39mreturn\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_active_spark_context\n",
      "File \u001b[0;32m~/spark/python/pyspark/context.py:195\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mif\u001b[39;00m gateway \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m gateway\u001b[39m.\u001b[39mgateway_parameters\u001b[39m.\u001b[39mauth_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    191\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m is not allowed as it is a security risk.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m     )\n\u001b[0;32m--> 195\u001b[0m SparkContext\u001b[39m.\u001b[39;49m_ensure_initialized(\u001b[39mself\u001b[39;49m, gateway\u001b[39m=\u001b[39;49mgateway, conf\u001b[39m=\u001b[39;49mconf)\n\u001b[1;32m    196\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_init(\n\u001b[1;32m    198\u001b[0m         master,\n\u001b[1;32m    199\u001b[0m         appName,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m         udf_profiler_cls,\n\u001b[1;32m    209\u001b[0m     )\n",
      "File \u001b[0;32m~/spark/python/pyspark/context.py:417\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mwith\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    416\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m SparkContext\u001b[39m.\u001b[39m_gateway:\n\u001b[0;32m--> 417\u001b[0m         SparkContext\u001b[39m.\u001b[39m_gateway \u001b[39m=\u001b[39m gateway \u001b[39mor\u001b[39;00m launch_gateway(conf)\n\u001b[1;32m    418\u001b[0m         SparkContext\u001b[39m.\u001b[39m_jvm \u001b[39m=\u001b[39m SparkContext\u001b[39m.\u001b[39m_gateway\u001b[39m.\u001b[39mjvm\n\u001b[1;32m    420\u001b[0m     \u001b[39mif\u001b[39;00m instance:\n",
      "File \u001b[0;32m~/spark/python/pyspark/java_gateway.py:103\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m proc\u001b[39m.\u001b[39mpoll() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(conn_info_file):\n\u001b[0;32m--> 103\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.1\u001b[39;49m)\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(conn_info_file):\n\u001b[1;32m    106\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mJava gateway process exited before sending its port number\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('test').master(\"yarn\") \\\n",
    ".config(\"spark.executor.instances\", 9) \\\n",
    ".config(\"spark.executor.memory\", \"1G\")  \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MUTE OUTPUT FROM SPARK\n",
    "logger = spark._jvm.org.apache.log4j\n",
    "logger.LogManager.getLogger(\"org\").setLevel(logger.Level.OFF)\n",
    "logger.LogManager.getLogger(\"akka\").setLevel(logger.Level.OFF)\n",
    "spark.conf.set(\"spark.driver.log.level\", \"OFF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Event, White, Black, Result, WhiteElo, BlackElo, Opening, TimeControl, Termination, Moves,Eval, UTCTimestamp\n",
    "schema = StructType([ \\\n",
    "    StructField(\"Event\",StringType(),True), \\\n",
    "    StructField(\"White\",StringType(),True), \\\n",
    "    StructField(\"Black\",StringType(),True), \\\n",
    "    StructField(\"Result\", StringType(), True), \\\n",
    "    StructField(\"WhiteElo\", IntegerType(), True), \\\n",
    "    StructField(\"BlackElo\", IntegerType(), True), \\\n",
    "    StructField(\"Opening\",StringType(),True), \\\n",
    "    StructField(\"TimeControl\",StringType(),True), \\\n",
    "    StructField(\"Termination\",StringType(),True), \\\n",
    "    StructField(\"Moves\", StringType(), True), \\\n",
    "    StructField(\"Eval\", StringType(), True), \\\n",
    "    StructField(\"UTCTimestamp\", TimestampType(), True) \\\n",
    "  ])\n",
    "df = spark.read.csv(\"hdfs://namenode:9000/chess_2016_dataset/output/part*\", schema=schema)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check Shape of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"shape: \", (df.count(), len(df.columns)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert columns to appropriate types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_types(df)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_difference = 3.0\n",
    "eval_games = df.where(col(\"Eval\")[0].isNotNull())\n",
    "eval_games = eval_games.withColumn(\"WhiteBlunders\", (find_white_blunders(col(\"Eval\"), lit(eval_difference))))\n",
    "eval_games = eval_games.withColumn(\"BlackBlunders\", (find_black_blunders(col(\"Eval\"), lit(eval_difference))))\n",
    "eval_games.select(\"TimeControl\", \"White\", \"WhiteElo\", \"WhiteBlunders\", \"Black\", \"BlackElo\", \"BlackBlunders\", \"Result\", \"Termination\") \\\n",
    "    .orderBy(col(\"WhiteBlunders\").desc(), col(\"BlackBlunders\").desc()).limit(10).toPandas().head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot Most Blundered Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "plot_eval_game(eval_games)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group By\n",
    "- Time control ~ (60, 120, 180, 600) etc...\n",
    "- Elo-Brackets ~ ([1200, 1400], [1500, 1700], [2000-2200]) etc..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Control Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_control_white_blunders_averages = eval_games \\\n",
    "    .groupBy(\"TimeControl\") \\\n",
    "    .agg(mean(\"WhiteBlunders\"), count(\"TimeControl\")) \\\n",
    "    .withColumn(\"avg(WhiteBlunders)\", format_number(\"avg(WhiteBlunders)\", 1))\n",
    "\n",
    "time_control_black_blunders_averages = eval_games \\\n",
    "    .groupBy(\"TimeControl\") \\\n",
    "    .agg(mean(\"BlackBlunders\"), count(\"TimeControl\")) \\\n",
    "    .withColumn(\"avg(BlackBlunders)\", format_number(\"avg(BlackBlunders)\", 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_control_white_blunders_averages \\\n",
    "    .orderBy(col(\"avg(WhiteBlunders)\").desc()) \\\n",
    "    .where(col(\"count(TimeControl)\")>1000) \\\n",
    "    .limit(10) \\\n",
    "    .toPandas() \\\n",
    "    .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_control_black_blunders_averages \\\n",
    "    .orderBy(col(\"avg(BlackBlunders)\").desc()) \\\n",
    "    .where(col(\"count(TimeControl)\")>1000) \\\n",
    "    .limit(10) \\\n",
    "    .toPandas() \\\n",
    "    .head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elo Brackets Grouping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start off by Creating a new spark daraframe column called \"EloBracket\" which we will later use to group and aggregrate by. When grouping the players by elo brackets we want to use a range that makes sense such that there are not 1 bracket that contains 80% of the playerbase and ones that only contain a small fraction. E.g We want evenly distributed amount of players in each bracket (as far as that is possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by getting all the elo column values in the dataframe.\n",
    "elo_list = eval_games.select(collect_list(\"WhiteElo\")).first()[0]\n",
    "sns.set_theme(style=\"ticks\")\n",
    "sns.set_style('darkgrid')\n",
    "sns.distplot(elo_list, kde=True, color ='green', bins=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"EloBracket\" column should be of type String and contain values in format: \"0-1200\", \"1200-1600\", \"1600-2000\", \"2000-3000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_games = eval_games.withColumn(\"EloBracket\", \\\n",
    "                         when((0 < eval_games.WhiteElo) & (eval_games.WhiteElo < 1500), lit(\"<1500\")) \\\n",
    "                        .when((1500 <= eval_games.WhiteElo) & (eval_games.WhiteElo <= 1750), lit(\"1500-1750\")) \\\n",
    "                        .when((1750 < eval_games.WhiteElo) & (eval_games.WhiteElo <= 2000), lit(\"1751-2000\")) \\\n",
    "                        .otherwise(lit(\">2000\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_games.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_bracket_white_blunders_averages = eval_games \\\n",
    "    .groupBy(\"EloBracket\") \\\n",
    "    .agg(mean(\"WhiteBlunders\"), count(\"EloBracket\")) \\\n",
    "    .withColumn(\"avg(WhiteBlunders)\", format_number(\"avg(WhiteBlunders)\", 1))\n",
    "\n",
    "elo_bracket_black_blunders_averages = eval_games \\\n",
    "    .groupBy(\"EloBracket\") \\\n",
    "    .agg(mean(\"BlackBlunders\"), count(\"EloBracket\")) \\\n",
    "    .withColumn(\"avg(BlackBlunders)\", format_number(\"avg(BlackBlunders)\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_bracket_white_blunders_averages.orderBy(col(\"avg(WhiteBlunders)\").desc()).limit(10).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_bracket_black_blunders_averages.orderBy(col(\"avg(BlackBlunders)\").desc()).limit(10).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = eval_games.select(\"Moves\") \\\n",
    "    .orderBy(col(\"WhiteBlunders\").desc(), col(\"BlackBlunders\").desc()) \\\n",
    "    .limit(1) \\\n",
    "    .take(1)[0][0]\n",
    "print([x.replace(\"'\",\"\").replace('\"', \"\").strip(\"'\") for x in a])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIG HEAVY FOOKIN WORK"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move List to FEN notation\n",
    "ta den lista me moves som input, lag en FEN string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = eval_games.select(\"Moves\").take(1)\n",
    "moves = rows[0].Moves\n",
    "moves"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First moves\n",
    "kan bruk d me elo og result for Ã¥ se ka som e vanlig for good players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = eval_games.select(\"Result\", \"WhiteElo\", \"BlackElo\", \"Moves\").take(100)\n",
    "\n",
    "first_moves = []\n",
    "for row in rows: \n",
    "    move = row.Moves[:2]\n",
    "    first_move = [row.Result, row.WhiteElo, row.BlackElo, move]\n",
    "    first_moves.append(first_move)\n",
    "\n",
    "first_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
